{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51aa7841-b833-493a-b621-ad2127da5036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea822c98-87cf-4a2b-a9f1-2df5082bb9b3",
   "metadata": {},
   "source": [
    "In this notebook, we read the ERA5 data stored on `/glade` and save the necessary variables in a more accessible manner locally. Specifically, we will read $u$, $v$, $w$, $T$, and $Z$ (where $Z$ is the geopotential), as well as the coordinate variables $\\vartheta$ and $p$. Seviour et al. (2012) suggest that six-hourly resolution is necessary to capture the diurnal variability of the residual upwelling. Fortunately, there is an ERA5 dataset on disk ([633.1](https://rda.ucar.edu/datasets/ds633.1/)) of monthly mean data derived from the original six-hourly resolution. To reduce the size of the data we store locally, we will only store DJF and JJA averages.\n",
    "\n",
    "We begin by setting the appropriate directory and enumerating the available years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f39b0bff-3e69-487c-b939-5ef18696edea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43 years of ERA5 data, starting with 1979 and ending with 2021.\n"
     ]
    }
   ],
   "source": [
    "era_dir = '/gpfs/fs1/collections/rda/data/ds633.1/e5.moda.an.pl'\n",
    "years = sorted(os.listdir(era_dir))\n",
    "n_year = len(years)\n",
    "\n",
    "print(f'Found {n_year} years of ERA5 data, starting with {years[0]} and ending with {years[-1]}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d23c1b-2703-4737-9765-15b116a76537",
   "metadata": {},
   "source": [
    "Now, we create arrays of the appropriate shape to hold the seasonal averages for each variable of interest. We also define indices that select the right months for each season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a05a8e29-28b7-47a5-a705-f2b48b40ae92",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lev, n_lat, n_lon = 37, 721, 1440\n",
    "# shape = (n_year, n_lev, n_lat, n_lon)\n",
    "shape = (n_lev, n_lat, n_lon)\n",
    "\n",
    "names = ['u', 'v', 'w', 'T', 'Z']\n",
    "data_djf = {name : np.zeros(shape) for name in names}\n",
    "data_jja = {name : np.zeros(shape) for name in names}\n",
    "\n",
    "idx_djf = np.array([11, 0, 1])\n",
    "idx_jja = np.array([5, 6, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608e2503-c4d5-4e00-bd45-7bab45114872",
   "metadata": {},
   "source": [
    "We are now ready to step through the years, selecting the appropriate file for each variable and computing the seasonal averages we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "271ef36b-0e0a-4c49-acee-6bcccd084063",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [26:14<00:00, 36.63s/year]\n"
     ]
    }
   ],
   "source": [
    "for year in tqdm(years, unit='year'):\n",
    "    year_dir = f'{era_dir}/{year}'\n",
    "    fnames = [x for x in os.listdir(year_dir) if x.endswith('.nc')]\n",
    "    \n",
    "    for name in names:\n",
    "        fname = [x for x in fnames if f'_{name.lower()}.' in x][0]\n",
    "        with xr.open_dataset(f'{year_dir}/{fname}') as f:\n",
    "            data_djf[name] += f[name.upper()][idx_djf].mean('time')\n",
    "            data_jja[name] += f[name.upper()][idx_jja].mean('time')\n",
    "            \n",
    "for name in names:\n",
    "    data_djf[name] = data_djf[name] / n_year\n",
    "    data_jja[name] = data_jja[name] / n_year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f56f09c-8708-4e92-a891-56c79a7a389c",
   "metadata": {},
   "source": [
    "Let's save these arrays to the disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c4faa55-89b5-4e9f-bfd4-f41777cd85cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('data/era-djf.npz', **data_djf)\n",
    "np.savez('data/era-jja.npz', **data_jja)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfba89c-d0aa-46a3-980c-95a50653c43b",
   "metadata": {},
   "source": [
    "Finally, we also want the pressure and latitude grids saved. We read and save them below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e8516bf-80a9-42a9-9317-d3523a854695",
   "metadata": {},
   "outputs": [],
   "source": [
    "with xr.open_dataset(f'{year_dir}/{fname}') as f:\n",
    "    p = f['level'].values\n",
    "    lat = f['latitude'].values\n",
    "    \n",
    "np.savez('data/era-coords.npz', p=p, lat=lat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pangeo (2019.09.12 - py3.7)",
   "language": "python",
   "name": "pangeo-2019.09.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
